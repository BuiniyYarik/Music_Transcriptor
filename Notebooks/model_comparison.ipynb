{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871caba60877edff",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:40:08.818674600Z",
     "start_time": "2023-11-05T12:40:06.901995900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from Data.preprocessing import DataPreprocessor\n",
    "from Models.first_cnn_topology import create_first_cnn_model\n",
    "from Models.second_cnn_topology import create_second_cnn_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:40:08.834693600Z",
     "start_time": "2023-11-05T12:40:08.819673400Z"
    }
   },
   "id": "e99a53d6f79b027a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file 1 of 10\n",
      "Loading file 2 of 10\n",
      "Loading file 3 of 10\n",
      "Loading file 4 of 10\n",
      "Loading file 5 of 10\n",
      "Loading file 6 of 10\n",
      "Loading file 7 of 10\n",
      "Loading file 8 of 10\n",
      "Loading file 9 of 10\n",
      "Loading file 10 of 10\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize Preprocessor\n",
    "preprocessor = DataPreprocessor(transform_type='fft', file_path=\"../Data/musicnet.npz\", metadata_path=\"../Data/musicnet_metadata.csv\")\n",
    "\n",
    "# Step 3: Load Data\n",
    "X, y = preprocessor.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:40:31.262767200Z",
     "start_time": "2023-11-05T12:40:08.836198200Z"
    }
   },
   "id": "4fd3ce6048cdd6b5"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned X shape: (33218, 2048, 10, 1)\n",
      "Partitioned y shape: (33218, 990)\n"
     ]
    }
   ],
   "source": [
    "def partition_data(data, window_size):\n",
    "    \"\"\"\n",
    "    Partition data into smaller segments of a given window size, padding if necessary.\n",
    "    :param data: List of 2D arrays.\n",
    "    :param window_size: The size of the window to partition each array.\n",
    "    :return: A new array with the partitioned data.\n",
    "    \"\"\"\n",
    "    partitioned_data = []\n",
    "    for array in data:\n",
    "        # Calculate the number of partitions for the current array\n",
    "        num_partitions = array.shape[1] // window_size\n",
    "        # Slice the array into partitions and append to the list\n",
    "        for i in range(num_partitions):\n",
    "            start = i * window_size\n",
    "            end = start + window_size\n",
    "            partitioned_data.append(array[:, start:end])\n",
    "        # Check if the last partition is smaller than the window_size\n",
    "        if array.shape[1] % window_size != 0:\n",
    "            # Pad the last partition with zeros\n",
    "            last_partition = array[:, -window_size:]\n",
    "            padding_width = window_size - last_partition.shape[1]\n",
    "            padding = np.zeros((array.shape[0], padding_width))\n",
    "            last_partition_padded = np.concatenate((last_partition, padding), axis=1)\n",
    "            partitioned_data.append(last_partition_padded)\n",
    "    # Stack all the partitions along a new axis\n",
    "    partitioned_data = np.stack(partitioned_data, axis=0)\n",
    "    return partitioned_data\n",
    "\n",
    "# Partition X and y with the modified function\n",
    "window_size = 10\n",
    "X_partitioned = partition_data(X, window_size)\n",
    "y_partitioned = partition_data(y, window_size)\n",
    "\n",
    "# Add a channel dimension to X\n",
    "X_partitioned = X_partitioned[..., np.newaxis]\n",
    "# Reshape y to be 2D\n",
    "y_partitioned = y_partitioned.reshape(y_partitioned.shape[0], -1)\n",
    "\n",
    "print(f\"Partitioned X shape: {X_partitioned.shape}\")\n",
    "print(f\"Partitioned y shape: {y_partitioned.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:50:57.205551900Z",
     "start_time": "2023-11-05T12:50:52.407559800Z"
    }
   },
   "id": "dd90399ea0709b79"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Step 5: Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_partitioned, y_partitioned, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:50:59.465556600Z",
     "start_time": "2023-11-05T12:50:57.207553900Z"
    }
   },
   "id": "a1a422cc02a88fde"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Step 6: Define Models\n",
    "input_shape = X_train.shape[1:]  # Assuming X_train is already in the correct shape\n",
    "num_classes = y_train.shape[1]   # Assuming y_train is one-hot encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:50:59.478556500Z",
     "start_time": "2023-11-05T12:50:59.461560400Z"
    }
   },
   "id": "a8cf4dba00ce4cb5"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model_1 = create_first_cnn_model(input_shape, num_classes)\n",
    "model_2 = create_second_cnn_model(input_shape, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:50:59.737556700Z",
     "start_time": "2023-11-05T12:50:59.477556700Z"
    }
   },
   "id": "e7fff159738b11e1"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Step 7: Compile Models\n",
    "optimizer = Adam()\n",
    "model_1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:50:59.753556300Z",
     "start_time": "2023-11-05T12:50:59.738557700Z"
    }
   },
   "id": "cf7d811c4bc6f293"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "748/748 [==============================] - 21s 27ms/step - loss: 27683262464.0000 - accuracy: 0.0195 - val_loss: 109550575616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "748/748 [==============================] - 20s 26ms/step - loss: 705578270720.0000 - accuracy: 0.0222 - val_loss: 1441391181824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "748/748 [==============================] - 20s 26ms/step - loss: 3783133233152.0000 - accuracy: 0.0215 - val_loss: 6010495827968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "748/748 [==============================] - 19s 26ms/step - loss: 11350721953792.0000 - accuracy: 0.0222 - val_loss: 15732888829952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "748/748 [==============================] - 19s 26ms/step - loss: 25344614596608.0000 - accuracy: 0.0209 - val_loss: 32607565774848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "748/748 [==============================] - 91s 122ms/step - loss: 47922162958336.0000 - accuracy: 0.0214 - val_loss: 58170365968384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "588/748 [======================>.......] - ETA: 46s - loss: 75886913126400.0000 - accuracy: 0.0213"
     ]
    }
   ],
   "source": [
    "# Step 8: Train Models\n",
    "history_1 = model_1.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
    "history_2 = model_2.fit(X_train, y_train, epochs=10, validation_split=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-05T12:50:59.757555700Z"
    }
   },
   "id": "840a742c7060bd34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 9: Evaluate Models\n",
    "score_1 = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "score_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Step 10: Compare Results\n",
    "print(f\"Model 1 - Loss: {score_1[0]}, Accuracy: {score_1[1]}\")\n",
    "print(f\"Model 2 - Loss: {score_2[0]}, Accuracy: {score_2[1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "121aceffb4475ce2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the training history for both models\n",
    "plt.plot(history_1.history['accuracy'], label='Model 1 Accuracy')\n",
    "plt.plot(history_1.history['val_accuracy'], label='Model 1 Validation Accuracy')\n",
    "plt.plot(history_2.history['accuracy'], label='Model 2 Accuracy')\n",
    "plt.plot(history_2.history['val_accuracy'], label='Model 2 Validation Accuracy')\n",
    "plt.title('Model Training History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T12:50:26.109591300Z"
    }
   },
   "id": "cbc3727d159c5c04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
